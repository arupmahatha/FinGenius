{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ API key loaded successfully!\n",
      "✓ First few characters: sk-ant-a...\n",
      "\n",
      "Analyzing: Is the stock worth investing\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To determine if a stock is worth investing, I need to analyze key metrics like price trends, trading volume, and volatility over a relevant time period. The consumption table seems to contain the necessary data.\n",
      "\n",
      "Action: sql_db_list_tables\n",
      "Action Input: \"\"\u001b[0m\u001b[38;5;200m\u001b[1;3mconsumption\u001b[0m\u001b[32;1m\u001b[1;3mThought: The consumption table appears to be the only relevant table, so I should query its schema to understand the available columns.\n",
      "\n",
      "Action: sql_db_schema\n",
      "Action Input: consumption\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE consumption (\n",
      "\t\"Unnamed: 0\" BIGINT, \n",
      "\t\"Date\" TEXT, \n",
      "\t\"Price\" FLOAT, \n",
      "\t\"Close\" FLOAT, \n",
      "\t\"High\" FLOAT, \n",
      "\t\"Low\" FLOAT, \n",
      "\t\"Open\" FLOAT, \n",
      "\t\"Volume\" FLOAT\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from consumption table:\n",
      "Unnamed: 0\tDate\tPrice\tClose\tHigh\tLow\tOpen\tVolume\n",
      "0\t2023-12-18\t194.9350128173828\t195.88999938964844\t196.6300048828125\t194.38999938964844\t196.08999633789065\t55751900.0\n",
      "1\t2023-12-19\t195.9798889160156\t196.94000244140625\t196.9499969482422\t195.88999938964844\t196.16000366210935\t40714100.0\n",
      "2\t2023-12-20\t193.88018798828125\t194.8300018310547\t197.67999267578125\t194.8300018310547\t196.8999938964844\t52242800.0\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mThought: To determine if the stock is worth investing, I need to analyze key metrics over a relevant time period, such as the last 6 months or 1 year. The consumption table contains useful data like closing prices, trading volume, and price ranges. I can query this data and calculate metrics like:\n",
      "\n",
      "- Recent price trends (increasing/decreasing)\n",
      "- Average trading volume and volume spikes \n",
      "- Volatility measured by price ranges\n",
      "- Any anomalous trading activity\n",
      "\n",
      "Action: sql_db_query_checker\n",
      "Action Input:\n",
      "WITH recent_data AS (\n",
      "  SELECT \n",
      "    date, \n",
      "    close AS closing_price,\n",
      "    high, \n",
      "    low,\n",
      "    open,\n",
      "    volume\n",
      "  FROM consumption\n",
      "  WHERE date >= date('now', '-6 months')\n",
      "  ORDER BY date\n",
      ")\n",
      "SELECT\n",
      "  -- Price Trends\n",
      "  ROUND(closing_price, 2) AS recent_closing_price,\n",
      "  ROUND(LAG(closing_price, 30) OVER (ORDER BY date), 2) AS closing_price_30d_ago, \n",
      "  ROUND(closing_price - LAG(closing_price, 30) OVER (ORDER BY date), 2) AS price_change_30d,\n",
      "  ROUND((closing_price - LAG(closing_price, 30) OVER (ORDER BY date)) / LAG(closing_price, 30) OVER (ORDER BY date) * 100, 2) AS price_change_pct_30d,\n",
      "  \n",
      "  -- Volume \n",
      "  ROUND(volume, 0) AS volume,\n",
      "  ROUND(AVG(volume) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 0) AS avg_vol_30d,\n",
      "  \n",
      "  -- Volatility\n",
      "  ROUND(MAX(high) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 2) AS high_30d,\n",
      "  ROUND(MIN(low) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 2) AS low_30d,\n",
      "  ROUND(MAX(high) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) - \n",
      "         MIN(low) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 2) AS price_range_30d\n",
      "         \n",
      "FROM recent_data\n",
      "ORDER BY date DESC\n",
      "LIMIT 10;\u001b[0m\u001b[36;1m\u001b[1;3mWITH recent_data AS (\n",
      "  SELECT \n",
      "    date, \n",
      "    close AS closing_price,\n",
      "    high, \n",
      "    low,\n",
      "    open,\n",
      "    volume\n",
      "  FROM consumption\n",
      "  WHERE date >= date('now', '-6 months')\n",
      "  ORDER BY date\n",
      ")\n",
      "SELECT\n",
      "  -- Price Trends\n",
      "  ROUND(closing_price, 2) AS recent_closing_price,\n",
      "  ROUND(LAG(closing_price, 30) OVER (ORDER BY date), 2) AS closing_price_30d_ago, \n",
      "  ROUND(closing_price - LAG(closing_price, 30) OVER (ORDER BY date), 2) AS price_change_30d,\n",
      "  ROUND((closing_price - LAG(closing_price, 30) OVER (ORDER BY date)) / LAG(closing_price, 30) OVER (ORDER BY date) * 100, 2) AS price_change_pct_30d,\n",
      "  \n",
      "  -- Volume \n",
      "  ROUND(volume, 0) AS volume,\n",
      "  ROUND(AVG(volume) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 0) AS avg_vol_30d,\n",
      "  \n",
      "  -- Volatility\n",
      "  ROUND(MAX(high) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 2) AS high_30d,\n",
      "  ROUND(MIN(low) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 2) AS low_30d,\n",
      "  ROUND(MAX(high) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) - \n",
      "         MIN(low) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 2) AS price_range_30d\n",
      "         \n",
      "FROM recent_data\n",
      "ORDER BY date DESC\n",
      "LIMIT 10;\u001b[0m\u001b[32;1m\u001b[1;3mThought: The query looks good and should provide the key metrics needed to analyze if the stock is worth investing over the recent 6 month period. It calculates:\n",
      "\n",
      "- Recent closing prices and 30-day price changes/percentages to show price trends\n",
      "- Daily trading volume and 30-day average volume to identify high volume periods\n",
      "- 30-day high, low, and price range to measure volatility\n",
      "\n",
      "I can execute this query on the consumption data to get the results.\n",
      "\n",
      "Action: sql_db_query\n",
      "Action Input: \n",
      "WITH recent_data AS (\n",
      "  SELECT \n",
      "    date,\n",
      "    close AS closing_price, \n",
      "    high,\n",
      "    low,\n",
      "    open,\n",
      "    volume\n",
      "  FROM consumption\n",
      "  WHERE date >= date('now', '-6 months')\n",
      "  ORDER BY date\n",
      ")\n",
      "SELECT\n",
      "  -- Price Trends\n",
      "  ROUND(closing_price, 2) AS recent_closing_price,\n",
      "  ROUND(LAG(closing_price, 30) OVER (ORDER BY date), 2) AS closing_price_30d_ago,\n",
      "  ROUND(closing_price - LAG(closing_price, 30) OVER (ORDER BY date), 2) AS price_change_30d,\n",
      "  ROUND((closing_price - LAG(closing_price, 30) OVER (ORDER BY date)) / LAG(closing_price, 30) OVER (ORDER BY date) * 100, 2) AS price_change_pct_30d,\n",
      "  \n",
      "  -- Volume\n",
      "  ROUND(volume, 0) AS volume, \n",
      "  ROUND(AVG(volume) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 0) AS avg_vol_30d,\n",
      "  \n",
      "  -- Volatility\n",
      "  ROUND(MAX(high) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 2) AS high_30d,\n",
      "  ROUND(MIN(low) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 2) AS low_30d,\n",
      "  ROUND(MAX(high) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) -\n",
      "         MIN(low) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 2) AS price_range_30d\n",
      "\n",
      "FROM recent_data\n",
      "ORDER BY date DESC\n",
      "LIMIT 10;\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[(251.04, 222.91, 28.13, 12.62, 51665600.0, 42633953.0, 251.38, 219.71, 31.67), (248.13, 225.91, 22.22, 9.84, 33155300.0, 43087657.0, 250.8, 219.71, 31.09), (247.96, 230.1, 17.86, 7.76, 32777500.0, 44128150.0, 250.8, 219.71, 31.09), (246.49, 233.67, 12.82, 5.49, 45205800.0, 44604597.0, 250.8, 219.71, 31.09), (247.77, 233.4, 14.37, 6.16, 36914800.0, 44278310.0, 248.21, 219.71, 28.5), (246.75, 231.41, 15.34, 6.63, 44649200.0, 44250720.0, 247.24, 219.71, 27.53), (242.84, 230.57, 12.27, 5.32, 36870600.0, 44055823.0, 244.63, 219.71, 24.92), (243.04, 230.76, 12.28, 5.32, 40033900.0, 43863787.0, 244.54, 219.71, 24.83), (243.01, 235.86, 7.15, 3.03, 44383900.0, 44272223.0, 244.11, 219.71, 24.4), (242.65, 236.48, 6.17, 2.61, 38861000.0, 44087647.0, 242.76, 219.71, 23.05)]\u001b[0mError: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `Here is my analysis on whether the stock is worth investing based on the recent 6 month data:\n",
      "\n",
      "1. Interpretation: The user is asking if the stock is currently a good investment opportunity based on its recent performance and trading activity.\n",
      "\n",
      "2. Thought Process: To evaluate if a stock is worth investing in, I need to analyze key metrics over a relevant recent time period, such as the last 6 months. The consumption table contains useful data like closing prices, trading volume, highs, and lows that I can use to calculate:\n",
      "\n",
      "- Price trends (increasing/decreasing prices, percent changes)\n",
      "- Trading volume levels and spikes \n",
      "- Volatility measured by price ranges\n",
      "\n",
      "By querying and calculating these metrics, I can look for patterns that may signal a good or poor investment.\n",
      "\n",
      "3. SQL Query: \n",
      "WITH recent_data AS (\n",
      "  SELECT\n",
      "    date,  \n",
      "    close AS closing_price,\n",
      "    high,\n",
      "    low, \n",
      "    open,\n",
      "    volume\n",
      "  FROM consumption\n",
      "  WHERE date >= date('now', '-6 months')\n",
      "  ORDER BY date  \n",
      ")\n",
      "SELECT\n",
      "  -- Price Trends\n",
      "  ROUND(closing_price, 2) AS recent_closing_price,\n",
      "  ROUND(LAG(closing_price, 30) OVER (ORDER BY date), 2) AS closing_price_30d_ago,\n",
      "  ROUND(closing_price - LAG(closing_price, 30) OVER (ORDER BY date), 2) AS price_change_30d,\n",
      "  ROUND((closing_price - LAG(closing_price, 30) OVER (ORDER BY date)) / LAG(closing_price, 30) OVER (ORDER BY date) * 100, 2) AS price_change_pct_30d,\n",
      "   \n",
      "  -- Volume\n",
      "  ROUND(volume, 0) AS volume,\n",
      "  ROUND(AVG(volume) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 0) AS avg_vol_30d,\n",
      "   \n",
      "  -- Volatility\n",
      "  ROUND(MAX(high) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 2) AS high_30d, \n",
      "  ROUND(MIN(low) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 2) AS low_30d,\n",
      "  ROUND(MAX(high) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) -\n",
      "         MIN(low) OVER (ORDER BY date ROWS BETWEEN 29 PRECEDING AND CURRENT ROW), 2) AS price_range_30d\n",
      "         \n",
      "FROM recent_data\n",
      "ORDER BY date DESC\n",
      "LIMIT 10;\n",
      "\n",
      "4. Results:\n",
      "\n",
      "recent_closing_price | closing_price_30d_ago | price_change_30d | price_change_pct_30d | volume | avg_vol_30d | high_30d | low_30d | price_range_30d\n",
      "-- | -- | -- | -- | -- | -- | -- | -- | --\n",
      "251.04 | 222.91 | 28.13 | 12.62 | 51665600 | 42633953 | 251.38 | 219.71 | 31.67\n",
      "248.13 | 225.91 | 22.22 | 9.84 | 33155300 | 43087657 | 250.8 | 219.71 | 31.09\n",
      "247.96 | 230.1 | 17.86 | 7.76 | 32777500 | 44128150 | 250.8 | 219.71 | 31.09\n",
      "246.49 | 233.67 | 12.82 | 5.49 | 45205800 | 44604597 | 250.8 | 219.71 | 31.09\n",
      "247.77 | 233.4 | 14.37 | 6.16 | 36914800 | 44278310 | 248.21 | 219.71 | 28.5\n",
      "246.75 | 231.41 | 15.34 | 6.63 | 44649200 | 44250720 | 247.24 | 219.71 `\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict, List, Optional\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('api_key.env')\n",
    "\n",
    "class ConfigError(Exception):\n",
    "    \"\"\"Custom exception for configuration errors\"\"\"\n",
    "    pass\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for the application.\"\"\"\n",
    "    db_path: str = \"apple_last_year_data.csv\"\n",
    "    sqlite_path: str = \"sqlite:///consumption.db\"\n",
    "    model_name: str = \"claude-3-sonnet-20240229\"\n",
    "    \n",
    "    @property\n",
    "    def api_key(self) -> str:\n",
    "        \"\"\"Securely get API key from environment variable.\"\"\"\n",
    "        api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "        if not api_key:\n",
    "            raise ConfigError(\n",
    "                \"ANTHROPIC_API_KEY not found in api_key.env file. \"\n",
    "                \"Please check if the file exists and contains: ANTHROPIC_API_KEY=your-key-here\"\n",
    "            )\n",
    "        return api_key\n",
    "\n",
    "class StockAnalyzer:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.db = self._init_database()\n",
    "        self.llm = self._init_llm()\n",
    "        self.agent = self._setup_agent()\n",
    "\n",
    "    def _init_database(self) -> SQLDatabase:\n",
    "        \"\"\"Initialize SQLite database from CSV.\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(self.config.db_path)\n",
    "            df.to_sql('consumption', 'sqlite:///consumption.db', index=False, if_exists='replace')\n",
    "            return SQLDatabase.from_uri(self.config.sqlite_path)\n",
    "        except FileNotFoundError:\n",
    "            raise ConfigError(f\"CSV file not found: {self.config.db_path}\")\n",
    "\n",
    "    def _init_llm(self) -> ChatAnthropic:\n",
    "        \"\"\"Initialize the language model.\"\"\"\n",
    "        return ChatAnthropic(\n",
    "            model=self.config.model_name,\n",
    "            temperature=0,\n",
    "            api_key=self.config.api_key\n",
    "        )\n",
    "\n",
    "    def _create_prompt(self, schema_info: str) -> str:\n",
    "        \"\"\"Create a detailed prompt for the SQL agent.\"\"\"\n",
    "        return f\"\"\"You are an expert financial database analyst. Your task is to:\n",
    "1. Interpret user questions about stock data\n",
    "2. Develop a clear thought process\n",
    "3. Create and execute appropriate SQL queries\n",
    "4. Present results clearly\n",
    "\n",
    "Available Schema:\n",
    "{schema_info}\n",
    "\n",
    "Example 1:\n",
    "User Question: \"How did Apple perform last month?\"\n",
    "Thought Process: We need to analyze key performance metrics for the previous month including price changes, trading volume, and volatility.\n",
    "SQL Query: \n",
    "WITH last_month AS (\n",
    "    SELECT \n",
    "        ROUND(MAX(close), 2) as highest_close,\n",
    "        ROUND(MIN(close), 2) as lowest_close,\n",
    "        ROUND(AVG(close), 2) as avg_close,\n",
    "        ROUND(((MAX(close) - MIN(close)) / MIN(close) * 100), 2) as price_range_percent,\n",
    "        ROUND(AVG(volume), 0) as avg_volume\n",
    "    FROM consumption \n",
    "    WHERE strftime('%m', date) = strftime('%m', date('now', '-1 month'))\n",
    ")\n",
    "SELECT * FROM last_month;\n",
    "\n",
    "Example 2:\n",
    "User Question: \"What were the highest volume trading days?\"\n",
    "Thought Process: We should identify days with exceptional trading volume and analyze the corresponding price movements.\n",
    "SQL Query:\n",
    "WITH avg_vol AS (\n",
    "    SELECT AVG(volume) as avg_daily_volume FROM consumption\n",
    ")\n",
    "SELECT \n",
    "    date,\n",
    "    ROUND(close, 2) as closing_price,\n",
    "    volume,\n",
    "    ROUND(volume / avg_daily_volume, 2) as volume_ratio\n",
    "FROM consumption, avg_vol\n",
    "WHERE volume > avg_daily_volume\n",
    "ORDER BY volume DESC\n",
    "LIMIT 5;\n",
    "\n",
    "Your Response Format:\n",
    "1. Interpretation: Explain what the user is asking for\n",
    "2. Thought Process: Detail your analytical approach\n",
    "3. SQL Query: Show the complete SQL query\n",
    "4. Results: Present the data in a clear format\n",
    "5. Analysis: Provide insights about the results\n",
    "\n",
    "Guidelines:\n",
    "- Round numeric values to 2 decimal places\n",
    "- Sort time-series data chronologically\n",
    "- Include relevant column headers\n",
    "- Show percentage changes where appropriate\n",
    "- Explain any notable patterns or anomalies\n",
    "- Handle edge cases and null values appropriately\"\"\"\n",
    "\n",
    "    def _setup_agent(self):\n",
    "        \"\"\"Set up the SQL agent with necessary tools and prompts.\"\"\"\n",
    "        toolkit = SQLDatabaseToolkit(db=self.db, llm=self.llm)\n",
    "        schema_info = self.db.get_table_info()\n",
    "        prompt = self._create_prompt(schema_info)\n",
    "        return create_sql_agent(\n",
    "            llm=self.llm,\n",
    "            toolkit=toolkit,\n",
    "            agent_type=\"zero-shot-react-description\",\n",
    "            verbose=True,\n",
    "            prefix=prompt\n",
    "        )\n",
    "\n",
    "    def analyze(self, query: str) -> Dict:\n",
    "        \"\"\"Analyze a stock-related query and return detailed results.\"\"\"\n",
    "        try:\n",
    "            # Execute query and get full response\n",
    "            result = self.agent.invoke({\n",
    "                \"input\": query\n",
    "            })\n",
    "            \n",
    "            # Parse the response to extract different components\n",
    "            response_text = result['output']\n",
    "            \n",
    "            # Extract components (this will vary based on actual output format)\n",
    "            components = self._parse_response(response_text)\n",
    "            \n",
    "            return {\n",
    "                \"user_question\": query,\n",
    "                \"interpretation\": components.get(\"interpretation\", \"\"),\n",
    "                \"thought_process\": components.get(\"thought_process\", \"\"),\n",
    "                \"sql_query\": components.get(\"sql_query\", \"\"),\n",
    "                \"results\": components.get(\"results\", []),\n",
    "                \"analysis\": components.get(\"analysis\", \"\")\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"error\": str(e),\n",
    "                \"user_question\": query\n",
    "            }\n",
    "\n",
    "    def _parse_response(self, response: str) -> Dict:\n",
    "        \"\"\"Parse the agent's response into structured components.\"\"\"\n",
    "        try:\n",
    "            # Split response into sections\n",
    "            sections = response.split('\\n')\n",
    "            current_section = \"\"\n",
    "            parsed = {\n",
    "                \"interpretation\": \"\",\n",
    "                \"thought_process\": \"\",\n",
    "                \"sql_query\": \"\",\n",
    "                \"results\": [],\n",
    "                \"analysis\": \"\"\n",
    "            }\n",
    "            \n",
    "            for line in sections:\n",
    "                if \"Thought:\" in line:\n",
    "                    current_section = \"thought_process\"\n",
    "                    parsed[current_section] = line.replace(\"Thought:\", \"\").strip()\n",
    "                elif \"SQL Query:\" in line:\n",
    "                    current_section = \"sql_query\"\n",
    "                    parsed[current_section] = line.replace(\"SQL Query:\", \"\").strip()\n",
    "                elif \"Result:\" in line or \"SQLResult:\" in line:\n",
    "                    current_section = \"results\"\n",
    "                    # Try to parse as DataFrame if possible\n",
    "                    try:\n",
    "                        result_str = line.split(\"SQLResult:\", 1)[1].strip()\n",
    "                        parsed[\"results\"] = pd.read_json(result_str).to_dict('records')\n",
    "                    except:\n",
    "                        parsed[\"results\"] = line.replace(\"Result:\", \"\").strip()\n",
    "                elif line.strip():\n",
    "                    parsed[current_section] += \"\\n\" + line.strip()\n",
    "            \n",
    "            return parsed\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing response: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "def test_connection():\n",
    "    \"\"\"Test if the API key is loaded correctly.\"\"\"\n",
    "    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    if api_key:\n",
    "        print(\"✓ API key loaded successfully!\")\n",
    "        print(f\"✓ First few characters: {api_key[:8]}...\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"✗ API key not found in api_key.env\")\n",
    "        print(\"Please ensure your api_key.env file contains: ANTHROPIC_API_KEY=your-key-here\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Test connection first\n",
    "        if not test_connection():\n",
    "            return\n",
    "\n",
    "        # Initialize analyzer\n",
    "        config = Config()\n",
    "        analyzer = StockAnalyzer(config)\n",
    "        \n",
    "        # Example queries\n",
    "        queries = [\n",
    "            # \"Show me the last 10 days of stock prices\",\n",
    "            # \"What's the average trading volume this month?\",\n",
    "            # \"Find days with unusual price movements\",\n",
    "            \"Is the stock worth investing\"\n",
    "        ]\n",
    "        \n",
    "        for query in queries:\n",
    "            print(f\"\\nAnalyzing: {query}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            result = analyzer.analyze(query)\n",
    "            \n",
    "            if \"error\" not in result:\n",
    "                print(\"Question:\", result[\"user_question\"])\n",
    "                print(\"\\nInterpretation:\", result[\"interpretation\"])\n",
    "                print(\"\\nThought Process:\", result[\"thought_process\"])\n",
    "                print(\"\\nSQL Query:\", result[\"sql_query\"])\n",
    "                print(\"\\nResults:\")\n",
    "                if isinstance(result[\"results\"], list):\n",
    "                    df = pd.DataFrame(result[\"results\"])\n",
    "                    print(df.to_string(index=False))\n",
    "                else:\n",
    "                    print(result[\"results\"])\n",
    "                print(\"\\nAnalysis:\", result[\"analysis\"])\n",
    "            else:\n",
    "                print(f\"Error: {result['error']}\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "                \n",
    "    except ConfigError as e:\n",
    "        print(f\"Configuration Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
